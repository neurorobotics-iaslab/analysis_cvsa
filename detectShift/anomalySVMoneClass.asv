%% Anomaly detection with one class SVM
close all; clear all; clc;
addpath('/home/paolo/cvsa_ws/src/analysis_cvsa/utils');

%% variables
bands = {[8 10], [10 12], [12 14], [14 16], [8 14]};
avg = 1;
bufferSize_integrator = 48;
chunkSize = 32;
nchannels = 39;
bufferSize_processing = 512;
filterOrder = 4;
classes = [730 731];
fix_event = 786;
cf_event = 781;
hit_event = 897;
miss_event = 898;
timeout_event = 899;
startTrial_event = 786; %% we use only data inside fix to boom
nclasses = length(classes);
channels_select = {'P3', 'PZ', 'P4', 'POZ', 'O1', 'O2', 'P5', 'P1', 'P2', 'P6', 'PO5', 'PO3', 'PO4', 'PO6', 'PO7', 'PO8', 'OZ'};
bands_str = cellfun(@(x) sprintf('%d-%d', x(1), x(2)), bands, 'UniformOutput', false);
nbands = length(bands);
signals = cell(1, nbands);
headers = cell(1, nbands);
for idx_band = 1:nbands
    headers{idx_band}.TYP = [];
    headers{idx_band}.DUR = [];
    headers{idx_band}.POS = [];
    headers{idx_band}.startNewFile = [];
    headers{idx_band}.ths_rejection = [];
    headers{idx_band}.ths = [];
    headers{idx_band}.bufferSize_integrator = [];
    headers{idx_band}.alpha = [];
    signals{idx_band} = [];
end

%% load the gdfs
[filenames, pathname] = uigetfile('*.gdf', 'Select GDF evaluation Files', 'MultiSelect', 'on');
if ischar(filenames)
    filenames = {filenames};
end

%% Concatenate all + processing + extract selected channels
nFiles = length(filenames);
hit = zeros(nFiles, 1); miss = zeros(nFiles, 1); timeout = zeros(nFiles, 1);
for idx_file= 1: nFiles
    fullpath_file = fullfile(pathname, filenames{idx_file});
    disp(['file (' num2str(idx_file) '/' num2str(nFiles)  '): ', filenames{idx_file}]);
    [signal,header] = sload(fullpath_file);
    signal = signal(:,1:nchannels);
    channels_label = header.Label;
    [~, idx_channels_select] = ismember(channels_select, channels_label);
    % load the parameters used in ros
    if contains(filenames{idx_file}, 'evaluation')
        parameters_file = [pathname(1:end-4) 'parameters/' filenames{idx_file}(1:end-3) 'yaml'];
        a = ReadYaml(parameters_file);
        ths_rejection = a.integrator.thresholds_rejection;
        ths = a.trainingCVSA_node.thresholds;
        if contains(filenames{idx_file}, 'expo')
            alpha = a.integrator.alpha;
        else
            bufferSize = a.integrator.buffer_size;
        end
    else
        ths_rejection = [0.5 0.5];
        ths = [1.0 1.0];
        alpha = 0.97;
        bufferSize = 48;
    end
    

    for idx_band = 1:nbands
        band = bands{idx_band};
        [signal_processed, header_processed] = processing_offline(signal, header, nchannels, bufferSize_processing, filterOrder, band, chunkSize);
        c_header = headers{idx_band};
        c_header.sampleRate = header_processed.SampleRate;
        c_header.channels_labels = header.Label;
        c_header.TYP = cat(1, c_header.TYP, header_processed.EVENT.TYP);
        c_header.DUR = cat(1, c_header.DUR, header_processed.EVENT.DUR);
        c_header.POS = cat(1, c_header.POS, header_processed.EVENT.POS + size(signals{idx_band}, 1));
        c_header.startNewFile = cat(1, c_header.startNewFile, size(signals{idx_band}, 1) + 1);

        signals{idx_band} = cat(1, signals{idx_band}, signal_processed(:,:));
        c_header.ths = cat(1, c_header.ths, repmat(ths,size(signal_processed, 1), 1));
        c_header.ths_rejection = cat(1, c_header.ths_rejection, repmat(ths_rejection, size(signal_processed, 1), 1));
        if contains(filenames{idx_file}, 'evaluation')
            if contains(filenames{idx_file}, 'expo')
                c_header.alpha = cat(1, c_header.alpha, repmat(alpha, size(signal_processed, 1), 1));
                c_header.bufferSize_integrator = cat(1, c_header.bufferSize_integrator, nan(size(signal_processed, 1), 1));
            else
                c_header.bufferSize_integrator = cat(1, c_header.bufferSize_integrator, repmat(bufferSize, size(signal_processed, 1), 1));
                c_header.alpha = cat(1, c_header.alpha, nan(size(signal_processed, 1), 1));
            end
        else
            c_header.alpha = cat(c_header.alpha, ones(size(signal_processed, 1), 1)*alpha);
            c_header.bufferSize_integrator = cat(1, c_header.bufferSize_integrator, ones(size(signal_processed, 1), 1) * bufferSize);
        end
        headers{idx_band} = c_header;
    end

    % for the accuracy
    hit(idx_file) = sum(header.EVENT.TYP == hit_event);
    miss(idx_file) = sum(header.EVENT.TYP == miss_event);
    timeout(idx_file) = sum(header.EVENT.TYP == timeout_event);
end

%% extract all data of the cf
% now data contains all the cf data and the info give the positions and
% durations
cf_data = cell(1, nbands); 
for idx_band = 1:nbands
    [cf_data{idx_band}, cf_info] = extract_event(signals{idx_band}, headers{idx_band}, classes, cf_event);
end

%% extract fix data
fix_data = cell(1, nbands);
for idx_band = 1:nbands
    [fix_data{idx_band}, fix_info] = extract_event(signals{idx_band}, headers{idx_band}, classes, fix_event);
end

%% load QDA and extract features
[filename_qda, path_qda] = uigetfile('*.yaml;*.yml', 'Select a YAML of the QDA File');
path_qda = fullfile(path_qda, filename_qda);

qda = loadQDA(path_qda);
cf_samples = features_extraction(cf_data, bands, qda.bands, qda.idchans);
fix_samples = features_extraction(fix_data, bands, qda.bands, qda.idchans);
typ = cf_data{1}.typ;

%% Save files
save("cvsa_ws/src/analysis_cvsa/detectShift/set_features.mat", "fix_samples", "fix_info", "cf_samples", "cf_info", "typ");
cf_814 = cf_data{5}.data;
fix_814 = fix_data{5}.data;
save("cvsa_ws/src/analysis_cvsa/detectShift/set_814.mat", "fix_814", "fix_info", "cf_814", "cf_info", "typ");
